{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.distributions.multivariate_normal import _batch_trtrs_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _batch_mahalanobis(bL, bx, fixed=False):\n",
    "    n = bx.size(-1)\n",
    "    if fixed:\n",
    "        # assume bL.shape = (i, j, n, n), bx.shape = (K, I, J, n)\n",
    "        # we are going to reshape bx into the shape (K, I/i, i, J/j, j, n)\n",
    "        # then permute the shape into (K, I/i, J/j, i, j, n)\n",
    "        bx_batch_shape = bx.shape[:-1]\n",
    "        bL_batch_dims = bL.dim() - 2\n",
    "        outer_batch_dims = len(bx_batch_shape) - bL_batch_dims\n",
    "        old_batch_dims = outer_batch_dims + bL_batch_dims\n",
    "        new_batch_dims = outer_batch_dims + 2 * bL_batch_dims\n",
    "        bx_new_shape = bx.shape[:outer_batch_dims]\n",
    "        for (s, S) in zip(bL.shape[:-2], bx.shape[outer_batch_dims:-1]):\n",
    "            bx_new_shape += (S // s, s)\n",
    "        bx_new_shape += (n,)\n",
    "        bx = bx.reshape(bx_new_shape)\n",
    "        permute_dims = (list(range(outer_batch_dims)) +\n",
    "                        list(range(outer_batch_dims, new_batch_dims, 2)) +\n",
    "                        list(range(outer_batch_dims + 1, new_batch_dims, 2)) +\n",
    "                        [new_batch_dims])\n",
    "        bx = bx.permute(permute_dims)\n",
    "    else:\n",
    "        bL = bL.expand(bx.shape[bx.dim() - bL.dim() + 1:] + (n,))\n",
    "    flat_L = bL.reshape(-1, n, n)  # shape = b x n x n\n",
    "    flat_x = bx.reshape(-1, flat_L.size(0), n)  # shape = c x b x n\n",
    "    flat_x_swap = flat_x.permute(1, 2, 0)  # shape = b x n x c\n",
    "    M_swap = _batch_trtrs_lower(flat_x_swap, flat_L).pow(2).sum(-2)  # shape = b x c\n",
    "    M = M_swap.t()  # shape = c x b\n",
    "    if fixed:\n",
    "        permuted_M = M.reshape(bx.shape[:-1])\n",
    "        permute_inv_dims = list(range(outer_batch_dims))\n",
    "        for i in range(bL_batch_dims):\n",
    "            permute_inv_dims += [outer_batch_dims + i, old_batch_dims + i]\n",
    "        reshaped_M = permuted_M.permute(permute_inv_dims)\n",
    "        return reshaped_M.reshape(bx_batch_shape)\n",
    "    else:\n",
    "        return M.reshape(bx.shape[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bL = torch.eye(8).expand(6, 1, 8, 8).contiguous().requires_grad_()\n",
    "bx = torch.randn(6, 8000, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare forward speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.72 s, sys: 47.7 ms, total: 2.77 s\n",
      "Wall time: 586 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "a = _batch_mahalanobis(bL, bx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46.5 ms, sys: 0 ns, total: 46.5 ms\n",
      "Wall time: 2.61 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "b = _batch_mahalanobis(bL, bx, fixed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare forward+backward speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 28s, sys: 11min 39s, total: 16min 7s\n",
      "Wall time: 1min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "c = torch.autograd.grad(_batch_mahalanobis(bL, bx).sum(), (bL,))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 91.5 ms, sys: 220 ms, total: 312 ms\n",
      "Wall time: 15.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "d = torch.autograd.grad(_batch_mahalanobis(bL, bx, fixed=True).sum(), (bL,))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### verify consistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1, dtype=torch.uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a == b).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1, dtype=torch.uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(c == d).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.4 version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _legacy_batch_mahalanobis(L, x):\n",
    "    flat_L = L.unsqueeze(0).reshape((-1,) + L.shape[-2:])\n",
    "    L_inv = torch.stack([torch.inverse(Li.t()) for Li in flat_L]).view(L.shape)\n",
    "    return (x.unsqueeze(-1) * L_inv).sum(-2).pow(2.0).sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.3 ms, sys: 109 ms, total: 135 ms\n",
      "Wall time: 6.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "e = _legacy_batch_mahalanobis(bL, bx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.73 ms ± 219 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "f = torch.autograd.grad(_legacy_batch_mahalanobis(bL, bx).sum(), (bL,))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inverse vs trtrs with event_dim=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bL = torch.eye(2).expand(6, 1, 2, 2).contiguous().requires_grad_()\n",
    "bx = torch.randn(6, 8000, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.92 ms ± 24.7 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "g = torch.autograd.grad(_batch_mahalanobis(bL, bx, fixed=True).sum(), (bL,))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.46 ms ± 12.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "h = torch.autograd.grad(_legacy_batch_mahalanobis(bL, bx).sum(), (bL,))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inverse vs trtrs with event_dim=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 8\n",
    "bL = torch.eye(N).expand(6, 1, N, N).contiguous().requires_grad_()\n",
    "bx = torch.randn(6, 8000, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.34 ms ± 69.9 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "g = torch.autograd.grad(_batch_mahalanobis(bL, bx, fixed=True).sum(), (bL,))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.03 ms ± 96 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "h = torch.autograd.grad(_legacy_batch_mahalanobis(bL, bx).sum(), (bL,))[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
